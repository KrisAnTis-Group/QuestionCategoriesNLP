#на этапе предварительного развет. анализа было решено проанализировать данные по следующим критериям:
# 1. определить количество обучающих текстов и тестовых, вывести пример обрабатываемого данного.
# 2. построить гистограмму частотности слов, обратить внимание на распределение гистограммы
# 3. определить количество уникальных токенов
# 4. отобразить 10% самых частотных слов
# 5. оценить процент заполненности матрицы признаков для обучающей и тестовой выборки
# 6. построить гистограмму распределения весов признаков
# 7. определить колличество уникальных классов (меток)
# 8. построить гистограмму распределения меток в обучающей и тестовой выборках
# 9. оценить отношение размера словаря к размеру текста
# 10. оценить процентное соотношение ненормативной лексики в словаре к размеру словаря
# 11. определить тональности текстов по оценки агрессивности

import numpy as np
import data
from data import get_DataSet_on_numpy

train_sourse = get_DataSet_on_numpy(subset = "train")
test_sourse = get_DataSet_on_numpy(subset = "test")

print('Количество обучающих текстов',len(train_sourse['data']))
print('Количество тестовых текстов',len(test_sourse['data']))
print()
print(train_sourse['data'][0].strip())
print()
print('Метка: ',train_sourse['target'][0])